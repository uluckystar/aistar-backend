
# 应用名称
spring.application.name=SpringAiStar

# Ollama服务的基础URL
spring.ai.ollama.base-url=http://localhost:11434

# 启用聊天功能
spring.ai.ollama.chat.enabled=true

# 使用的模型
spring.ai.ollama.chat.options.model=qwen2

# 温度：用于调节生成文本的多样性的温度参数。默认值为0.8
spring.ai.ollama.chat.options.temperature=0.8

# 上下文数量
spring.ai.ollama.chat.options.num-ctx=2048

# 启用嵌入功能
spring.ai.ollama.embedding.enabled=true

# 线程数量
spring.ai.ollama.chat.options.num-thread=8

# 连接池配置
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=30000
spring.datasource.hikari.max-lifetime=1800000
spring.datasource.hikari.connection-timeout=30000

# 设置调试日志级别
logging.level.io.jsonwebtoken=DEBUG
#logging.level.org.springframework.security=DEBUG
logging.level.com.localaihub.aistar=DEBUG

# 设置日志文件输出
logging.file.name=logs/ollama.log
logging.level.root=INFO


# 编码配置
server.servlet.encoding.charset=UTF-8
server.servlet.encoding.enabled=true
server.servlet.encoding.force=true

spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration

spring.security.user.name=star
spring.security.user.password=aistar
spring.security.user.roles=USER

jwt.secret=3xj8FbVQX4P6Fe0Zp+9L3utWZKZY1Dm+bo4Wl1+NiEMCM3QqfMaWmrZbgOQkSYc9Hb1fvCk0YFAqS+CnD6ABaw==
# 10 hour in milliseconds
jwt.expiration=36000000

####################################  可选的  ############################################################
## 下面是一些可选配置参数，默认情况下它们已被注释掉

# 输出格式：指定聊天结果的输出格式。当前唯一接受的值为 json
#spring.ai.ollama.chat.options.format=json

# 保持连接活动的时间：控制模型在请求后加载到内存中的时间。默认值为5分钟
# spring.ai.ollama.chat.options.keep_alive=5m

# 是否使用NUMA：控制是否使用非均匀内存访问架构。默认值为false
# spring.ai.ollama.chat.options.numa=false

# 批量大小：每次推理请求中的输入批量大小。默认值为512
# spring.ai.ollama.chat.options.num-batch=512

# GPU数量：要发送到GPU的层数。默认值为-1表示自动选择
# spring.ai.ollama.chat.options.num-gpu=-1

# 主GPU设备：指定主要使用的GPU设备编号或名称。默认值为空
# spring.ai.ollama.chat.options.main-gpu=-

# 低VRAM模式：是否启用低VRAM模式。默认值为false
# spring.ai.ollama.chat.options.low-vram=false

# 使用f16 kv：是否使用f16计算精度。默认值为true
# spring.ai.ollama.chat.options.f16-kv=true

# 是否记录所有logits：是否记录所有的logits值。默认值为false
# spring.ai.ollama.chat.options.logits-all=false

# 仅限于词汇表：是否仅使用词汇表中的单词进行推理。默认值为false
# spring.ai.ollama.chat.options.vocab-only=false

# 使用内存映射：是否使用内存映射来加速数据访问。默认值为true
# spring.ai.ollama.chat.options.use-mmap=true

# 锁定内存：是否锁定内存以提高性能。默认值为false
# spring.ai.ollama.chat.options.use-mlock=false

# 线程数量：设置计算期间使用的线程数。默认值为0表示由运行时决定
# spring.ai.ollama.chat.options.num-thread=0

# 保留数量：每个对话上下文中保留的历史输入数量。默认值为0
# spring.ai.ollama.chat.options.num-keep=0

# 随机种子：设置用于生成的随机数种子。默认值为-1表示使用系统默认值
# spring.ai.ollama.chat.options.seed=-1

# 预测数量：每次推理请求中的预测数量。默认值为-1表示自动选择
# spring.ai.ollama.chat.options.num-predict=-1

# Top-k值：用于减少生成无意义文本的概率。默认值为40
# spring.ai.ollama.chat.options.top-k=40

# Top-p值：与Top-k一起工作，用于控制生成文本的多样性。默认值为0.9
# spring.ai.ollama.chat.options.top-p=0.9

# TFS Z值：用于抑制未知输出的参数。默认值为1.0
# spring.ai.ollama.chat.options.tfs-z=1.0

# 典型P值：用于控制输出文本的一致性和多样性。默认值为1.0
# spring.ai.ollama.chat.options.typical-p=1.0

# 重复上次n值：设置模型查看以防止重复的历史输入的数量。默认值为64
# spring.ai.ollama.chat.options.repeat-last-n=64

# 重复惩罚：用于抑制重复文本生成的惩罚参数。默认值为1.1
# spring.ai.ollama.chat.options.repeat-penalty=1.1

# 存在惩罚：用于抑制生成包含特定单词的文本的惩罚参数。默认值为0.0
# spring.ai.ollama.chat.options.presence-penalty=0.0

# 频率惩罚：用于抑制频繁生成某些单词的惩罚参数。默认值为0.0
# spring.ai.ollama.chat.options.frequency-penalty=0.0

# Mirostat：启用Mirostat采样以控制困惑度。默认值为0（禁用）
# spring.ai.ollama.chat.options.mirostat=0

# Mirostat Tau值：控制输出一致性和多样性之间的平衡。默认值为5.0
# spring.ai.ollama.chat.options.mirostat-tau=5.0

# Mirostat Eta值：影响算法对生成文本反馈的响应速度。默认值为0.1
# spring.ai.ollama.chat.options.mirostat-eta=0.1

# 换行符惩罚：是否惩罚生成换行符的参数。默认值为true
# spring.ai.ollama.chat.options.penalize-newline=true

# 停止标志：设置停止生成文本的模式。默认值为空
# spring.ai.ollama.chat.options.stop=-
################################################################################################


